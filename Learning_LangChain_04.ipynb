{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzz3j+Y01hT4CV8RfbkcyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahzaibkhan/learning-langchain/blob/main/Learning_LangChain_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment analysis with ChatGPT and LangChain**\n",
        "Sentiment analysis is the process of analyzing digital text to determine if the emotional tone of the message is positive, negative, or neutral. Today, companies have large volumes of text data like emails, customer support chat transcripts, social media comments, and reviews.\n",
        "\n",
        "Before we begin, let’s make sure that you have the necessary prerequisites to follow along with this tutorial. You will need a valid OpenAI API key, Python installed on your computer or use Google colab, and the OpenAI API Python package installed. If you don’t have any of these, you can follow the instructions on the OpenAI website to get started.\n",
        "\n",
        "Since we are using Google Colab, we will be installing our prerequisites here.\n",
        "\n",
        "Now, let’s import the necessary libraries:"
      ],
      "metadata": {
        "id": "eQ1bfb78Stkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain\n",
        "!pip install -qU openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q0oNCVsTchE",
        "outputId": "9e6326dd-e1df-462f-dbde-ba30f548356a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XkPd6ANASl9p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Not the best of practices to place your API key openly, but for practice best to place and then later remove.\n",
        "# You can get your OPEN AI Key from their website\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let’s define a function that takes a text input and returns the sentiment analysis result.\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "def get_sentiment(text):\n",
        "  llm = OpenAI(temperature=0.9)\n",
        "  text = \"Sentiment analysis: {text}\"\n",
        "  sentiment = llm(text)\n",
        "  return sentiment"
      ],
      "metadata": {
        "id": "URbF9Fo2UxDf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this function, we are using the **Completion.create** method of the OpenAI API to get the sentiment analysis result. We are using the **text-davinci-002** engine for this task, which is a powerful language model developed by OpenAI. The prompt parameter is used to provide the input text to the model, and the other parameters are used to control the behavior of the model."
      ],
      "metadata": {
        "id": "S5GLwQ8lVLII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the function to return sentiment\n",
        "text = \"He has that aura that no body can match\"\n",
        "sentiment = get_sentiment(text)\n",
        "print(f\"{sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8QV5ewLVK2i",
        "outputId": "add32651-83c0-4762-8d53-ecb31adfb8f4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This text expresses a positive sentiment. The language is upbeat and hopeful, suggesting optimism and a hopeful outlook on the future. The speaker expresses a desire to move forward and make progress.\n"
          ]
        }
      ]
    }
  ]
}